\documentclass[notitlepage]{article}
\usepackage[utf8]{inputenc} 
\usepackage{geometry} 		
\usepackage{chngcntr}
\usepackage{amsmath} 			
\usepackage{amssymb}			
\usepackage{mathtools}		
\usepackage{comment} 			
\usepackage{mdframed}			
\usepackage{xcolor}				
\usepackage{fancyhdr}			
\usepackage{listings}			
\usepackage{color}				
\usepackage{tikz}	
\usepackage{tasks}			
\usepackage{exsheets}	
\usepackage{blindtext}	
\usepackage{array}			
\usepackage{empheq}
\usepackage{caption}
\usepackage{pdfpages}
\usepackage{tabularx}
\usepackage{lscape}

\geometry{ 						%Format titlepage (interrupted by newgeometry)
	a4paper,
	total={170mm,257mm}%,
	%left=0mm,
	%top=0mm,
}

%START DEFINE YOUR VARIABLES HERE

\newcommand{\documentName}{Software Design Specification}
\newcommand{\projectName}{Label Refinement by Behavioral Similarity}

%END DEFINE YOUR VARIABLES HERE

\title{%
	\documentName\text{ } \\
  \large \projectName\text{ } \\
  }

\author{
	\large \underline{Document owners:}\\ 
	Bianka Bakullari\\
	\texttt{}
	Christopher Beine\\
	\texttt{}
	Nicole Ventsch\\
	\texttt{}
	Juan Garza\\
	\texttt{}
}

\date{\small{Last edited: \today}}

\pagestyle{fancy}
\fancyhf{}
\rhead{}
\lhead{\documentName\space-\space\projectName}

\makeatletter					%Prefix to add ToC to titlepage
\newcommand*{\toccontents}{\@starttoc{toc}}
\renewcommand*\contentsname{}
\makeatother
                  

\begin{document}

\begin{titlepage}
\clearpage\maketitle			%Clear title page
\thispagestyle{fancy}
\tableofcontents
\end{titlepage}

\rfoot{\thepage}				%Start printing page-numbers, after title page.

\newgeometry{ 					%Default page formatting on-going #1
	total={170mm,257mm},
	left=20mm,
	top=25mm,
    bottom=30mm					%Causes warning
}

\begin{flushleft}				%Default page formatting on-going #2


\section{Introduction}
\subsection{System Overview}
\subsection{Design Map}
\subsection{Supporting Materials}
\subsection{Definitions and Acronyms}

\section{Design Considerations}
\subsection{Assumptions and Dependencies}
\subsection{General Constraints}
\subsection{Goals and Guidelines}
\subsection{Development Methods}

\section{Architectural Strategies}

\section{System Architecture}
The following UML displays the main applicaton components and where they are deployed. The final application will be deployed on an applicaton servers which the 
user can access over an Internet Browser on his own Machine. Therefore the System is independent of the users operating system. There are two option to perfom the 
algorithm:

\begin{itemize}
	\item 1. The user can access the JavaScript Front-end application via HTTP which provides an user friendly UI. There the user can set all required parameters and send them to the API.
	\item 2. Additional, the user can access the API directly via HTTP with the required parameter. So the application can integrate into other application which could be helpful to perfom preprocessing steps or to use the refined labels in another application. .
\end{itemize}


\includegraphics[scale=0.4]{"UML_Architecture/Architecture Overview".png}

\subsection{Client Machine}
The Client Machine is just a device with internet connection. It is not directly part of the application but is required to access to functionality.
To use the User Webinterface a Google Chrome or Mozilla Firefox Browser is required. The Client does not need a special operating system or system structure to user 
the project application.
\subsection{Front-end}
The Front-end provides the User Interface for a simple application access. It is created with HTML5 and JavaScript and redirects the User inputs to API.
So the end user must not know the API interface, required data formats and protocols.
\subsection{Refining Label API}
The Refining Label API is the main access point for the refining algorithm. Every communication goes through this API. After sending data, 
the API will validate them, execute some preprocessing steps like file conversion and finally execute the refining algorithm and returning the result to the calling user or system. 
Additional the API acts as a connection between the other Modules. Is connects the user access, algorithm and file handling.
Therefore each of the other components is independent and low coupling and high cohesion is achieved   
\subsection{File Store}
The File Store is an abstraction layer for the servers file system. It will keep track on the updates files and offers functions to store 
refined XES files on the server. It also monitors the memory utilization.
\subsection{Refining Event Labels}
The Refining Event Label components is responsible for the final refining algorithm. 
It contains functionality to calculate costs, execute preprocessing steps, horizontal clustering of variants and the vertical refinement.
To offer a maintainable and extensible system this compontent will provides interfaces to exchange mentioned functionalities. 
The following subcomponents exist: 


\subsection{Event Log Converter}submodules
The Event Log Converter is a Framework to convert different files types into an Event Log and convert them back into files. 
For our project the system provides functionality for XES and CSV import and export. 
The Framework can easily be extended with additional file types without changing the core functionality.

The following UML class diagram display the class structure.

\begin{landscape}
\includegraphics[width=\columnwidth]{"UML_Architecture/Event Log Converter CD".png}
\end{landscape}






\section{Policies and Tactics}


\subsection{Ensuring Requirements Realization}
To ensure the realization of all requirements specified in the Requirement Specification Document, the corresponding modules have to be designed.
The table below describes which modules are resposible for which requirement and which functionalities are used for the implementation of the module. \\

\medskip
%\newpage
\begin{tabularx}{\textwidth}{|p{6cm}|p{5cm}|p{6cm}}
\hline
\textbf{Requirements} 
&\textbf{Modules}
&\textbf{Functionalities}
\\
\hline
-Upload CSV event log file 
\newline -Upload XES event log file 
& 
1.1 File Converter 
\newline 1.2 Preprocessing log 
& 
1.1.1 get\_event\_from\_file() 
\newline 1.1.2 read\_XES()
\newline 1.2.1 check\_event\_log() 
\newline 1.2.2 lookup\_table() 
\newline 1.2.3 get\_variants \\
\hline
-Customize threshold for cost function
\newline -Customize horizontal threshold
\newline -Customize vertical threshold
\newline -Choose set of imprecise labels
&
2. Customize
&
2.1 set\_candiadates()
\newline 2.2 get\_candiadates()
\newline 2.3 set\_threshold()
\newline 2.4 get\_vertical\_threshold()
\newline 2.5 get\_horizontal\_threshold()
\\
\hline
-Calculate costs
&
3. Cost function
&
3.1 mappings()
\newline 3.2 cost\_mapping()
\newline 3.3 cost\_matrix()
\newline 3.4 graph()
\\ 
\hline
-Clustering of traces
\newline -Refine labels horizontally across traces 
&
4. Horizontal clustering of variantes
&
4.1 cluster\_detection\_relation()
\newline 4.2 refinement()
	\\ 
\hline
-Refine labels vertically within traces
&
5. Vertical refinement
&
5.1 relabel()
	\\ 
\hline
$- -$
&
6. Post-Processing
&
6.1 update\_map()
\newline 6.2 update\_table()	\\ 
\hline
-Download refined XES event log file
&
7. File Creator
&
6.1 create\_file()
\newline 6.2 store\_file()
\\ 
\hline
\end{tabularx} \\

\medskip

A detailed description of the modules and funcionalities is given in Section 6.



















\section{Detailed System Design}
The main algorithm "Refining Event Labels" will be split up into multiple modules that contain the main parts of the algorithm. These modules will be explained in detail in the following subsections.
\subsection{Module 1.1: File Converter}
\textit{Name}: File Creator

\textit{Type}: module

\textit{Description}: This module is responsible for creating a table from the data the user uploads. The event log provided by the user is read and stored internally containing all the original columns. 

\textit{Attributes}: None

\textit{Resources}: None

\textit{Operations}: 
\medskip

\par
\begingroup
\leftskip4em
\textbf{1.1.1}

\textit{Name}: get\_event\_log\_from\_file()

\textit{Arguments}: path to a log file in csv format or XES format

\textit{Returns}: event log in XES format

\textit{Description}: The file at the path the user enters is read and stored in XES format. In case the file is originally in csv format, the file is first converted to XES format and then stored.

\textit{Precondition}: the path provided by the user leads to a csv file or an XES file

\textit{Postcondition}: the table is stored internally as an XES file

\textit{Exceptions}: None
\par
\endgroup

\medskip

\par
\begingroup
\leftskip4em
\textbf{1.1.2}

\textit{Name}: read\_XES()

\textit{Arguments}: file in XES format

\textit{Returns}: event log 

\textit{Description}: The XES file is read and stored as a table containing the original columns.

\textit{Precondition}: an XES file was created using get\_event\_log\_from\_file()

\textit{Postcondition}: a table containing all original columns is stored internally 

\textit{Exceptions}: None
\par
\endgroup

\medskip

\subsection{Module 1.2: Preprocessing Log}
\textit{Name}: Preprocessing Log

\textit{Type}: module

\textit{Description}: This module is responsible for preprocessing the data. It is checked if the table provided by the user contains the right variables and an error is produced if is does not have. Moreover, a table containing all unique traces and the list of IDs corresponding to these traces is created.

\textit{Attributes}: None

\textit{Resources}: None

\textit{Operations: }
\medskip


\par
\begingroup
\leftskip4em
\textbf{1.2.1} 

\textit{Name}: check\_event\_log()

\textit{Arguments}: table imported using read\_XES() 

\textit{Returns}: Boolean (True or False)

\textit{Description}: It is checked whether the table is actually an event log, i.e., whether it contains an activity column, an ID column and a time stamp column. If these exist in the table, "True" will be returned, otherwise "False" will be returned. 

\textit{Precondition}: a file was created using read\_XES()

\textit{Postcondition}: if "True" is returned, the file is actually an event log, otherwise the file does not contain the necessary variables and an error will be displayed

\textit{Exceptions}: None
\par
\endgroup

\medskip

\par
\begingroup
\leftskip4em
\textbf{1.2.2}

\textit{Name}: lookup\_table()

\textit{Arguments}: table with all original columns

\textit{Returns}: lookup table containing a "variants" column and an "ID" column

\textit{Description}: The table is converted, so that we get a table containing the unique variants for the IDs ordered by their time stamp and the set of IDs corresponding to the variant. In this lookup table, the variants are stored as arrays and the corresponding IDs as a list.

\textit{Precondition}: the provided file is an event log

\textit{Postcondition}: a lookup table is stored containing the variants and IDs corresponding to those variants

\textit{Exceptions}: None

\par
\endgroup

\medskip

\par
\begingroup
\leftskip4em
\textbf{1.2.3}

\textit{Name}: get\_variants()

\textit{Arguments}: look-up table with variants and IDs for each variant

\textit{Returns}: set of unique trace variants

\textit{Description}: We create a set containing all the variants so that we can approach them when calculating the mappings later. Here we do not need to have access to the IDs.

\textit{Precondition}: The first column of the look-up table contains all trace variants

\textit{Postcondition}: a non-empty set containing the arrays describing each variant

\textit{Exceptions}: None

\par
\endgroup

\subsection{Module 2: Customize}
\textit{Name}: Customize

\textit{Type}: module

\textit{Description}: This module is responsible to customize the algorithm parameters. The module serves as a model class and will later pass to the refining algorithm.
It stores information about the candidates to refine, and the vertical and horizontal threshold. Also it will automatically validate this data.  

\textit{Attributes}: None

\textit{Resources}: None

\textit{Operations}: 
\medskip


\par
\begingroup
\leftskip4em
\textbf{2.1} 

\textit{Name}: set\_candiadates()

\textit{Arguments}: traces for which should be refined.

\textit{Returns}: void

\textit{Description}: The function provides functionality to stores the traces for the final refining algorithm. 

\textit{Precondition}: Valid trace model

\textit{Postcondition}: traces are stored in the model

\textit{Exceptions}: None

\par
\endgroup

\medskip


\par
\begingroup
\leftskip4em
\textbf{2.2} 

\textit{Name}: get\_candiadates()

\textit{Arguments}: none.

\textit{Returns}: Array of traces which sould be considered by the refining algorithm.

\textit{Description}: Provides access to all traces 

\textit{Precondition}: none.

\textit{Postcondition}: none.

\textit{Exceptions}: None
\par
\endgroup

\par
\begingroup
\leftskip4em
\textbf{2.3} 

\textit{Name}: set\_threshold()

\textit{Arguments}: vertical and horizontal threshold as double values.

\textit{Returns}: void

\textit{Description}: Allows to set the threshold for the horizontal and vertical refinement. Valous bigger than 1 will be converted to 0.99 and values smaller than 0 will be converted to 0.1

\textit{Precondition}: none.

\textit{Postcondition}: none.

\textit{Exceptions}: None
\par
\endgroup

\par
\begingroup
\leftskip4em
\textbf{2.4} 

\textit{Name}: get\_vertical\_threshold()

\textit{Arguments}: none.

\textit{Returns}: vertical threshold as double

\textit{Description}: function return the vertical threshold

\textit{Precondition}: none.

\textit{Postcondition}: none.

\textit{Exceptions}: None
\par
\endgroup

\par
\begingroup
\leftskip4em
\textbf{2.5} 

\textit{Name}: get\_horizontal\_threshold()

\textit{Arguments}: none.

\textit{Returns}: horizontal threshold as double

\textit{Description}: function return the vertical threshold

\textit{Precondition}: none.

\textit{Postcondition}: none.

\textit{Exceptions}: None
\par
\endgroup


\subsection{Module 3: Cost function}
\textit{Name}: Cost function

\textit{Type}: module

\textit{Description}: This module is responsible for calculating the costs of all mappings between each pair of variants and selecting the optimal mapping with the least costs. 

\textit{Attributes}: None

\textit{Resources}: The weights used for the calculation of costs

\textit{Operations}: 
\medskip

\par
\begingroup
\leftskip4em
\textbf{3.1} 

\textit{Name}: mappings()

\textit{Arguments}: two distinct trace variants 

\textit{Returns}: a set of possible mappings

\textit{Description}: For each pair of variants we obtain the set of common activity labels occurring in both variants. If this set is empty, no mapping is possible. Otherwise, if none of the common labels appears more than once in any of the variants, the unique mapping is yielded. In the other case, all combinations of possible mappings are yielded as a set where each mapping is an array of pairs of the positions that were matched together.

\textit{Precondition}: We go through all pairs of trace variants yielded by get\_variants()

\textit{Postcondition}: For each mapping, the cost function is computed

\textit{Exceptions}: None
\par
\endgroup


\medskip

\par
\begingroup
\leftskip4em
\textbf{3.2} 

\textit{Name}: cost\_mapping()

\textit{Arguments}: two trace variants and a mapping between them

\textit{Returns}: the cost of the mapping as a real number

\textit{Description}: For each pair in the mapping we count the number of distinct predecessors and successors and the distances to other matched pairs. We sum over these costs for all matched pairs and also add the number of unmatched labels appearing in the traces. Each summand is weighted with a corresponding weight.
Simultaneously we save all costs between pairs of variants in a list so that we can pick the minimal one.

\textit{Precondition}: We calculate the costs for each mapping yielded by mappings().

\textit{Postcondition}: For each mapping, the corresponding cost is computed.

\textit{Exceptions}: None
\par
\endgroup


\medskip

\par
\begingroup
\leftskip4em
\textbf{3.3} 

\textit{Name}: cost\_matrix()

\textit{Arguments}: the cost of the optimal mapping for each pair of variants

\textit{Returns}: a symmetrical 2-dimensional matrix

\textit{Description}: The matrix contains 0s in the diagonal and the entry in position $[i][j]$ corresponds to the cost of the optimal mapping between variant $i$ and variant $j$. 

\textit{Precondition}: We can obtain the cost of the optimal mapping between two variants by choosing the minimal entry in the list of costs of their possible mappings saved in cost\_mapping().

\textit{Postcondition}: For each pair of variants, the cost of the optimal mapping is known.

\textit{Exceptions}: None
\par
\endgroup


\medskip

\par
\begingroup
\leftskip4em
\textbf{3.4} 

\textit{Name}: graph()

\textit{Arguments}: the cost of the optimal mapping for each pair of variants and the set of variants

\textit{Returns}: a connected graph

\textit{Description}: For each variant there is a set of vertices corresponding to the events occuring in the variant. Each edge only connects matched pairs and for the pairs being in the candidate set the weight of each edge corresponds to the cost of the optimal mapping. Otherwise the weight of the edge is 0.

\textit{Precondition}: The weights for the edges are obtained from the cost\_matrix().

\textit{Postcondition}: Each variants has to be identifiable in the graph in order to be able to do the horizontal and vertical refinements in the next steps.

\textit{Exceptions}: None
\par
\endgroup


\subsection{Module 4: Horizontal clustering of variants}
\textit{Name}: Label refinement based on clusters

\textit{Type}: module

\textit{Description}: This module clusters the event log and perfoms the label refinement based on these clusters.

\textit{Attributes}: \begin{itemize}
	\item Event Log graph which should be refined 
	\item Customize object for the horizontal thresholds.
\end{itemize}

\textit{Resources}: none.

\textit{Operations}: 
\medskip

\par
\begingroup
\leftskip4em
\textbf{4.1} 

\textit{Name}: cluster\_detection\_relation()

\textit{Arguments}:  

\textit{Returns}: void.

\textit{Description}: Finds clusters inside.

\textit{Precondition}: An event log graph with related costs.

\textit{Postcondition}: The same graph object with detected clusters.

\textit{Exceptions}: None
\par
\endgroup

\medskip

\par
\begingroup
\leftskip4em
\textbf{4.2} 

\textit{Name}: refinement()

\textit{Arguments}: none.

\textit{Returns}: A horizontal clustered graph.

\textit{Description}: This method executes required steps to cluster a graph horizontal.

\textit{Precondition}: A already clustered graph.

\textit{Postcondition}: The same graph object with horizontal refined labels.

\textit{Exceptions}: None
\par
\endgroup


\textcolor{red}{Operations: clusterdetectionrelation, refinement}

\subsection{Module 5: Vertical Refinement}
\textit{Name}: Label refinement within variant

\textit{Type}: module

\textit{Description}: This module execute the label refinement within variant for the Event log and is part of the refinment algorithm.

\textit{Attributes}: none.

\textit{Resources}: none.

\textit{Operations}: 
\medskip

\par
\begingroup
\leftskip4em
\textbf{5.1} 

\textit{Name}: relabel()

\textit{Arguments}: a graph, the associated cluster and the customization Object for the horizontal threshold, 

\textit{Returns}: The realbeld graph

\textit{Description}: Performs the vertical label refinement for the refinment algorithm.

\textit{Precondition}: An already horizontal refined graph.

\textit{Postcondition}: The same graph object with vertical refined labels.

\textit{Exceptions}: None
\par
\endgroup




\subsection{Module 6: Post-Processing}
\textit{Name}: Embed refinements into original log 

\textit{Type}: module

\textit{Description}: This module is responsible for executing the refinements in the log level. That is, we want to go recreate the original event log with refined labels.

\textit{Attributes}: The graph containing the new labels for each variant

\textit{Resources}: The initial table describing the original event log

\textit{Operations}: 
\medskip

\par
\begingroup
\leftskip4em
\textbf{6.1} 

\textit{Name}: update\_map()

\textit{Arguments}: a graph and the look-up map

\textit{Returns}: the updated look-up with refined labels

\textit{Description}: We replace each old variant in the look-up map with the new refined one.

\textit{Precondition}: We have to be able to relate each old variant to its corresponding refined version.

\textit{Postcondition}: For each refined variant, we still have the list of the corresponding case IDs.

\textit{Exceptions}: None
\par
\endgroup


\medskip

\par
\begingroup
\leftskip4em
\textbf{6.2} 

\textit{Name}: update\_table()

\textit{Arguments}: the updated look-up map

\textit{Returns}: the updated table with refined labels for the complete log

\textit{Description}: We replace each old variant in the initial table map with the new refined one.

\textit{Precondition}: We use the case IDs to be able to substitute the old variants with the new ones.

\textit{Postcondition}: The updated table contains all original information from the event log but with refined candidate labels.

\textit{Exceptions}: None
\par
\endgroup




\subsection{Module 7: File Creator}
\textit{Name}: File Creator

\textit{Type}: module

\textit{Description}: Utility class to export and store an Event Logs as a XES file.

\textit{Attributes}: An Event Log model

\textit{Resources}: none.

\textit{Operations}: 
\medskip
\par
\begingroup
\leftskip4em
\textbf{6.1} 

\textit{Name}: create\_file()

\textit{Arguments}: Event Log model.

\textit{Returns}: void.

\textit{Description}: Converts the event logs a XSD file.

\textit{Precondition}: A valid event log format.

\textit{Postcondition}: a XSD file is created.

\textit{Exceptions}: None
\par
\endgroup

\medskip
\par
\begingroup
\leftskip4em
\textbf{6.2} 

\textit{Name}: store\_file()

\textit{Arguments}: A directory path.

\textit{Returns}: the create file path.

\textit{Description}: Stores the previous created file at given location.

\textit{Precondition}: A existing directory Path.

\textit{Postcondition}: the XSD file is stored.

\textit{Exceptions}: NotADirectoryException
\par
\endgroup





\section{User Interface Design}
\subsection{Application Control}

In the project, we will implement a web service. The web client will have a rather plain design that should focus on the main activities the service should provide, which are uploading event logs in csv or XES format, setting the threshold for the label refinement algorithm and download the refined log after the algorithm is finished. There will be buttons used to upload the file, apply the algorithm and download the refined event log. Moreover, the screens will have short explanations telling the user what to do (if not self-explanatory). For setting the thresholds, two boxes will be provided that include the default thresholds, but new values can be entered by the user. A draft of each of the main screen can be found in the next section, section 6.2.

\subsection{The Screens}

The main screens will be visualized in the following subsections. In these screens include the main functionalities, which are described in the former section. The following diagram will show the flow of control through the screens.  

\includegraphics[scale=0.7]{ScreenFlow.png}

\subsubsection{Screen 1}

\includegraphics[scale=0.8]{InterfaceMockup1.png}


The first screen visible to the user will show a description saying that an event log in csv of XES format should be uploaded. Moreover, a button "Upload File" is visible. By using this button, the user will continue to Screen 2. At the end of the page, there will be a link called "User Documentation". By clicking on this link, the User Documentation will be downloaded in pdf format.
\subsubsection{Screen 2}

\includegraphics[scale=0.9]{InterfaceMockup2.png}

In the second screen visible to the user, the user can enter the file direction of the event log he wants to upload. He can either directly type in the direction into the "File Direction" field or use the "search for File" button to search for a file on his pc, so that the direction will automatically be filled in after selecting a file.

After using one of this alternatives, he can use the "Upload" button to upload the file with the given directory. In case this file is an event log, i.e., the data contains at least the attributes "id", "time stamp" and "activity name", and has either csv or XES format, the user will continue to Screen 3.1. If one of these conditions is not satisfied, he will continue to Screen 3.2. 


\subsubsection{Screen 3.1}
\includegraphics[scale=0.9]{InterfaceMockup3-1.png}

This screen appears if the file uploaded by the user meets the requirements. In this screen, the user can set the thresholds for the algorithm, i.e., the variant and the unfolding threshold. He can enter these in the corresponding white boxes. If he does not enter the thresholds, the default values of 0.05 and 0.60 will be used respectively. Using the button "Apply the Algorithm", the web service will start applying the algorithm using the provided thresholds. After the algorithm is finished, the user will get to Screen 4.

\subsubsection{Screen 3.2}
\includegraphics[scale=0.9]{InterfaceMockup3-2.png}

This screen appears if the upload was not successful because the file did not meet the assumptions. If the file does not have the right format, the user can click on the button "Upload new File" to return to Screen 2 and upload a file that meets the constraints.


\subsubsection{Screen 4}
\includegraphics[scale=0.8]{InterfaceMockup4.png}

This Screen will be shown after finishing the algorithm. The user can now download the refined log using the corresponding button. After this step, the user is done and can exit the page, but if he also wants to apply the algorithm to another event log or to the same event log using different thresholds, he can use the corresponding buttons and will be redirected to Screen 2 or Screen 3.1 respectively.


%\newpage
%\bibliographystyle{plain}
%\bibliography{references}  




%\addcontentsline{toc}{chapter}{\textbf{References}}
\end{flushleft}
%\bibliography{uw-ethesis}
% Tip 5: You can create multiple .bib files to organize your references. 
% Just list them all in the \bibliogaphy command, separated by commas (no spaces).

% The following statement causes the specified references to be added to the bibliography% even if they were not 
% cited in the text. The asterisk is a wildcard that causes all entries in the bibliographic database to be included (optional).


\begin{thebibliography}{5}
\bibitem{paper}
Lu, Xixi, et al. "Handling duplicated tasks in process discovery by refining event labels." International Conference on Business Process Management. Springer, Cham, 2016.

\bibitem{matchings}
Xixi Lu1, Dirk Fahland, Frank J.H.M. van den Biggelaar, Wil M.P. van der Aalst. "Detecting Deviating Behaviors without Models."


\end{thebibliography}










\end{document}
